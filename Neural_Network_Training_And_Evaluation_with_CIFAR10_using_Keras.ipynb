{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.constraints import maxnorm\nfrom keras.layers import Activation\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom keras.utils import np_utils\nimport tensorflow as tf\nimport multiprocessing as mp","metadata":{"id":"2eJ5b_DYq6WB","execution":{"iopub.status.busy":"2022-02-12T17:42:09.153525Z","iopub.execute_input":"2022-02-12T17:42:09.153840Z","iopub.status.idle":"2022-02-12T17:42:09.161078Z","shell.execute_reply.started":"2022-02-12T17:42:09.153786Z","shell.execute_reply":"2022-02-12T17:42:09.160446Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from keras.datasets import cifar10\nnum_classes = 10\nepochs = 50 \ndata_augmentation = True\n\n(x_train, y_train), (x_test, y_test) = cifar10.load_data() \nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n\nclass_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n\ny_train = np_utils.to_categorical(y_train, num_classes)\ny_test = np_utils.to_categorical(y_test, num_classes)\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train  /= 255\nx_test /= 255","metadata":{"id":"QCKR0ZzXX66W","outputId":"825e85bb-88ba-4367-b91c-f8226c0eadff","execution":{"iopub.status.busy":"2022-02-12T17:42:09.162853Z","iopub.execute_input":"2022-02-12T17:42:09.163301Z","iopub.status.idle":"2022-02-12T17:42:10.321020Z","shell.execute_reply.started":"2022-02-12T17:42:09.163270Z","shell.execute_reply":"2022-02-12T17:42:10.320227Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def NetA():\n    model = Sequential()\n    model.add(Dense(16, input_shape=x_train.shape[1:]))\n    model.add(Flatten())\n    model.add(Dense(num_classes))\n    model.add(Activation('softmax'))\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\nnet_A = NetA()\nnet_A.summary()\n\nNetA = net_A.fit(x_train, y_train, batch_size=25, epochs=epochs, validation_data=(x_test,y_test),shuffle=True)","metadata":{"id":"lXRM3bEcZx5G","outputId":"6d1e004e-0332-4445-b38e-8e1b8ea73d0c","execution":{"iopub.status.busy":"2022-02-12T17:42:10.322226Z","iopub.execute_input":"2022-02-12T17:42:10.322525Z","iopub.status.idle":"2022-02-12T17:48:46.774666Z","shell.execute_reply.started":"2022-02-12T17:42:10.322483Z","shell.execute_reply":"2022-02-12T17:48:46.773427Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Plots for training and testing process: loss and accuracy\nplt.figure(0)\nplt.plot(NetA.history['accuracy'],'r')\nplt.plot(NetA.history['val_accuracy'],'g')\nplt.xticks(np.arange(0, 11, 2.0))\nplt.rcParams['figure.figsize'] = (8, 6)\nplt.xlabel(\"Num of Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Training Accuracy vs Validation Accuracy\")\nplt.legend(['train','validation'])\n\nplt.figure(1)\nplt.plot(NetA.history['loss'],'r')\nplt.plot(NetA.history['val_loss'],'g')\nplt.xticks(np.arange(0, 11, 2.0))\nplt.rcParams['figure.figsize'] = (8, 6)\nplt.xlabel(\"Num of Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training Loss vs Validation Loss\")\nplt.legend(['train','validation'])\nplt.show()\n\nscores = net_A.evaluate(x_test, y_test, verbose=0)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"id":"5aT9DGsnXQ8Z","outputId":"1e3dd3f4-0136-4de8-af30-9030ff581d2c","execution":{"iopub.status.busy":"2022-02-12T17:48:46.777546Z","iopub.execute_input":"2022-02-12T17:48:46.777793Z","iopub.status.idle":"2022-02-12T17:48:49.122307Z","shell.execute_reply.started":"2022-02-12T17:48:46.777764Z","shell.execute_reply":"2022-02-12T17:48:49.121667Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix result\nfrom sklearn.metrics import classification_report, confusion_matrix\nY_pred = net_A.predict(x_test, verbose=2)\ny_pred = np.argmax(Y_pred, axis=1)\n\nfor ix in range(10):\n    print(ix, confusion_matrix(np.argmax(y_test,axis=1),y_pred)[ix].sum())\ncm_A = confusion_matrix(np.argmax(y_test,axis=1),y_pred)\nprint(cm_A)\n\n# Visualizing of confusion matrix\nimport seaborn as sn\nimport pandas  as pd\ndf_cm_A = pd.DataFrame(cm_A, range(10),range(10))\nplt.figure(figsize = (10,7))\nsn.set(font_scale=1.4)\nsn.heatmap(df_cm_A, annot=True,annot_kws={\"size\": 12})\nplt.show()","metadata":{"id":"Wd_YPDmFXT-y","outputId":"65c66fd7-b5aa-4ac9-cfb4-986cacab3c91","execution":{"iopub.status.busy":"2022-02-12T17:48:49.123492Z","iopub.execute_input":"2022-02-12T17:48:49.123975Z","iopub.status.idle":"2022-02-12T17:48:58.730198Z","shell.execute_reply.started":"2022-02-12T17:48:49.123920Z","shell.execute_reply":"2022-02-12T17:48:58.729645Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def NetB():\n    model = Sequential()\n    model.add(Dense(16, input_shape=x_train.shape[1:]))\n    model.add(Flatten())\n    model.add(Dense(300))\n    model.add(Activation('relu'))\n    model.add(Dense(num_classes))\n    model.add(Activation('softmax'))\n\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\nnet_B = NetB()\nnet_B.summary()\nNetB = net_B.fit(x_train, y_train, batch_size=32, epochs=epochs, validation_data=(x_test,y_test),shuffle=True)","metadata":{"id":"w5V4HeswWzwC","outputId":"0f5b6c65-4017-4e69-d997-5a6dbc88a768","execution":{"iopub.status.busy":"2022-02-12T17:51:23.040163Z","iopub.execute_input":"2022-02-12T17:51:23.040450Z","iopub.status.idle":"2022-02-12T18:33:50.837103Z","shell.execute_reply.started":"2022-02-12T17:51:23.040418Z","shell.execute_reply":"2022-02-12T18:33:50.836319Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Plots for training and testing process: loss and accuracy\nplt.figure(0)\nplt.plot(NetB.history['accuracy'],'r')\nplt.plot(NetB.history['val_accuracy'],'g')\nplt.xticks(np.arange(0, 11, 2.0))\nplt.rcParams['figure.figsize'] = (8, 6)\nplt.xlabel(\"Num of Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Training Accuracy vs Validation Accuracy\")\nplt.legend(['train','validation'])\n\nplt.figure(1)\nplt.plot(NetB.history['loss'],'r')\nplt.plot(NetB.history['val_loss'],'g')\nplt.xticks(np.arange(0, 11, 2.0))\nplt.rcParams['figure.figsize'] = (8, 6)\nplt.xlabel(\"Num of Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training Loss vs Validation Loss\")\nplt.legend(['train','validation'])\nplt.show()\n\nscores = net_B.evaluate(x_test, y_test, verbose=0)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"id":"QqYxJ6mda3Fe","outputId":"301f3e1c-bbfb-4075-82a5-2ffa9e236e16","execution":{"iopub.status.busy":"2022-02-12T18:33:50.839070Z","iopub.execute_input":"2022-02-12T18:33:50.839588Z","iopub.status.idle":"2022-02-12T18:33:53.650077Z","shell.execute_reply.started":"2022-02-12T18:33:50.839551Z","shell.execute_reply":"2022-02-12T18:33:53.649195Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix result\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nY_pred = net_B.predict(x_test, verbose=2)\ny_pred = np.argmax(Y_pred, axis=1)\n\nfor ix in range(10):\n    print(ix, confusion_matrix(np.argmax(y_test,axis=1),y_pred)[ix].sum())\ncm_B= confusion_matrix(np.argmax(y_test,axis=1),y_pred)\nprint(cm_B)\n\n# Visualizing of confusion matrix\nimport seaborn as sn\nimport pandas  as pd\ndf_cm_B = pd.DataFrame(cm_B, range(10),range(10))\nplt.figure(figsize = (10,7))\nsn.set(font_scale=1.4)\nsn.heatmap(df_cm_B, annot=True,annot_kws={\"size\": 12})\nplt.show()","metadata":{"id":"p1jB1yUwbIpG","outputId":"7d539763-4f9c-469c-e7fa-fded5cfe729b","execution":{"iopub.status.busy":"2022-02-12T18:33:53.651792Z","iopub.execute_input":"2022-02-12T18:33:53.652101Z","iopub.status.idle":"2022-02-12T18:33:56.854820Z","shell.execute_reply.started":"2022-02-12T18:33:53.652060Z","shell.execute_reply":"2022-02-12T18:33:56.853995Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def NetC():\n    model = Sequential()\n    model.add(Dense(16, input_shape=x_train.shape[1:]))\n    model.add(Conv2D(25,(5, 5)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Flatten())\n    model.add(Dense(num_classes))\n    model.add(Activation('softmax'))\n\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\nnet_C = NetC()\nnet_C.summary()\n\nNetC = net_C.fit(x_train, y_train, batch_size=25, epochs=epochs, validation_data=(x_test,y_test),shuffle=True)","metadata":{"id":"jotBGndVYv-O","outputId":"8ef9d950-b1d4-4598-cfe1-0671b814b037","execution":{"iopub.status.busy":"2022-02-12T18:34:02.089393Z","iopub.execute_input":"2022-02-12T18:34:02.089714Z","iopub.status.idle":"2022-02-12T19:07:57.567764Z","shell.execute_reply.started":"2022-02-12T18:34:02.089677Z","shell.execute_reply":"2022-02-12T19:07:57.566859Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Plots for training and testing process: loss and accuracy\nplt.figure(0)\nplt.plot(NetC.history['accuracy'],'r')\nplt.plot(NetC.history['val_accuracy'],'g')\nplt.xticks(np.arange(0, 11, 2.0))\nplt.rcParams['figure.figsize'] = (8, 6)\nplt.xlabel(\"Num of Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Training Accuracy vs Validation Accuracy\")\nplt.legend(['train','validation'])\n\nplt.figure(1)\nplt.plot(NetC.history['loss'],'r')\nplt.plot(NetC.history['val_loss'],'g')\nplt.xticks(np.arange(0, 11, 2.0))\nplt.rcParams['figure.figsize'] = (8, 6)\nplt.xlabel(\"Num of Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training Loss vs Validation Loss\")\nplt.legend(['train','validation'])\nplt.show()\n\nscores = net_C.evaluate(x_test, y_test, verbose=0)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"id":"T6SMhZ1lcPxe","execution":{"iopub.status.busy":"2022-02-12T19:08:48.589165Z","iopub.execute_input":"2022-02-12T19:08:48.590180Z","iopub.status.idle":"2022-02-12T19:09:14.984898Z","shell.execute_reply.started":"2022-02-12T19:08:48.590119Z","shell.execute_reply":"2022-02-12T19:09:14.983863Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix result\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nY_pred = net_C.predict(x_test, verbose=2)\ny_pred = np.argmax(Y_pred, axis=1)\n\nfor ix in range(10):\n    print(ix, confusion_matrix(np.argmax(y_test,axis=1),y_pred)[ix].sum())\ncm_C = confusion_matrix(np.argmax(y_test,axis=1),y_pred)\nprint(cm_C)\n\n# Visualizing of confusion matrix\nimport seaborn as sn\nimport pandas  as pd\ndf_cm_C = pd.DataFrame(cm_C, range(10),range(10))\nplt.figure(figsize = (10,7))\nsn.set(font_scale=1.4)#for label size\nsn.heatmap(df_cm_C, annot=True,annot_kws={\"size\": 12})# font size\nplt.show()","metadata":{"id":"2EKpv7rlcLYy","execution":{"iopub.status.busy":"2022-02-12T19:09:31.460172Z","iopub.execute_input":"2022-02-12T19:09:31.460841Z","iopub.status.idle":"2022-02-12T19:09:34.697909Z","shell.execute_reply.started":"2022-02-12T19:09:31.460796Z","shell.execute_reply":"2022-02-12T19:09:34.694153Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"**INFERENCE:**\n* In NetA we have got an accuracy of 39.34%\n* In NetB we have got an accuracy of 50.63% which is better than our NetA\n* In NetC we have got an accuracy of 64.97% which is better than our both the previous networks\n","metadata":{}}]}